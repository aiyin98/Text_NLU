{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a4b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import glob\n",
    "import regex \n",
    "import re, nltk\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3c3ed",
   "metadata": {},
   "source": [
    "POS (Part of Speech) Tagging using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8beca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He --> PRON\n",
      "went --> VERB\n",
      "to --> PART\n",
      "play --> VERB\n",
      "basketball --> NOUN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Or you can use the type() function to check the type of nlp\n",
    "result = type(nlp) is spacy.language.Language\n",
    "\n",
    "# Create an nlp object\n",
    "doc = nlp(\"He went to play basketball\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the token and its part-of-speech tag\n",
    "    print(token.text, \"-->\", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f83d69",
   "metadata": {},
   "source": [
    "Dependency Parsing using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70514d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect the date at the start of the line to make each row unique.\n",
    "def DateTime(s):\n",
    "    regex_format = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -' \n",
    "    result = re.match(regex_format, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the group chat participant names\n",
    "def Participants(a):\n",
    "  a=a.split(\":\")\n",
    "  if len(a)==2:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "# Function to organize the data properly to be represented as a pandas dataframe\n",
    "def GetDataPoints(line):   \n",
    "    splitLine = line.split(' - ') \n",
    "    dateTime = splitLine[0]\n",
    "    date, time = dateTime.split(', ') \n",
    "    message = ' '.join(splitLine[1:])\n",
    "    if Participants(message): \n",
    "        splitMessage = message.split(': ') \n",
    "        participants = splitMessage[0] \n",
    "        message = ' '.join(splitMessage[1:])\n",
    "    else:\n",
    "        participants = None\n",
    "    return date, time, participants, message\n",
    "\n",
    " # Function to extract the emojis and add them to a new column\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade478e3",
   "metadata": {},
   "source": [
    "Read WhatsApp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d939ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "parsedData=[]\n",
    "data = [] \n",
    "text_data = '/Users/aiyinchen/Documents/NLU Project/WhatsApp Chat with Nic - Baddy Coaching.txt' # replace with the file name of your text data\n",
    "with open(text_data, encoding=\"utf-8\") as fp: #fp stands for file pointer and helps in reading in the data\n",
    "    fp.readline()\n",
    "    messageBuffer = [] \n",
    "    date, time, participants = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline() \n",
    "        if not line: \n",
    "            break\n",
    "        line = line.strip() \n",
    "        if DateTime(line): \n",
    "            if len(messageBuffer)> 0: \n",
    "                parsedData.append([date, time, participants, ' '.join(messageBuffer)]) \n",
    "            messageBuffer.clear() \n",
    "            date, time, participants, message = GetDataPoints(line) \n",
    "            messageBuffer.append(message) \n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1d55a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Participants</th>\n",
       "      <th>Message</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>15:44</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Hi Nic, this is Aiyin here.. We were in touch ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>15:45</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>I just checked, i didnt manage to book 9-10pm ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>15:52</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Hi Aiyin, 6-7pm is not a problem</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>15:53</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>My time is usually very flexible as long I don...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16:22</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Thats perfect! I'll bring shuttles for the day...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16:23</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Thanks. Just want to improve on general play</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16:24</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Probably have a lot of bad habits. Struggle to...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16:26</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Ahh okayy lets see what we can work on for Wed...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>16:27</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Me too! Thanks</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>23:45</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Hi Aiyin, is this at the Moberly Sports Centre...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>18:14</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Hey Nic, yes its at Moberly on Wed</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>00:39</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Hi Nic, you able to come slightly earlier at 5...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>00:53</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Sure! See you then</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:01</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Sorry running 10min late. Took a long time to ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:03</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>No problem at all, see you in a bit!</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:37</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>Just let them know you're  here for badminton ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:38</td>\n",
       "      <td>Aiyin 🔥</td>\n",
       "      <td>We're on court 5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:40</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Ok.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:40</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Just got here</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>17:40</td>\n",
       "      <td>Nic Baddy Coaching</td>\n",
       "      <td>Will get changed first</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time        Participants  \\\n",
       "0  2023-09-01  15:44             Aiyin 🔥   \n",
       "1  2023-09-01  15:45             Aiyin 🔥   \n",
       "2  2023-09-01  15:52  Nic Baddy Coaching   \n",
       "3  2023-09-01  15:53  Nic Baddy Coaching   \n",
       "4  2023-09-01  16:22             Aiyin 🔥   \n",
       "5  2023-09-01  16:23  Nic Baddy Coaching   \n",
       "6  2023-09-01  16:24  Nic Baddy Coaching   \n",
       "7  2023-09-01  16:26             Aiyin 🔥   \n",
       "8  2023-09-01  16:27  Nic Baddy Coaching   \n",
       "9  2023-09-02  23:45  Nic Baddy Coaching   \n",
       "10 2023-09-03  18:14             Aiyin 🔥   \n",
       "11 2023-09-06  00:39             Aiyin 🔥   \n",
       "12 2023-09-06  00:53  Nic Baddy Coaching   \n",
       "13 2023-09-06  17:01  Nic Baddy Coaching   \n",
       "14 2023-09-06  17:03             Aiyin 🔥   \n",
       "15 2023-09-06  17:37             Aiyin 🔥   \n",
       "16 2023-09-06  17:38             Aiyin 🔥   \n",
       "17 2023-09-06  17:40  Nic Baddy Coaching   \n",
       "18 2023-09-06  17:40  Nic Baddy Coaching   \n",
       "19 2023-09-06  17:40  Nic Baddy Coaching   \n",
       "\n",
       "                                              Message emoji  \n",
       "0   Hi Nic, this is Aiyin here.. We were in touch ...    []  \n",
       "1   I just checked, i didnt manage to book 9-10pm ...    []  \n",
       "2                    Hi Aiyin, 6-7pm is not a problem    []  \n",
       "3   My time is usually very flexible as long I don...    []  \n",
       "4   Thats perfect! I'll bring shuttles for the day...    []  \n",
       "5        Thanks. Just want to improve on general play    []  \n",
       "6   Probably have a lot of bad habits. Struggle to...    []  \n",
       "7   Ahh okayy lets see what we can work on for Wed...    []  \n",
       "8                                      Me too! Thanks    []  \n",
       "9   Hi Aiyin, is this at the Moberly Sports Centre...    []  \n",
       "10                 Hey Nic, yes its at Moberly on Wed    []  \n",
       "11  Hi Nic, you able to come slightly earlier at 5...    []  \n",
       "12                                 Sure! See you then    []  \n",
       "13  Sorry running 10min late. Took a long time to ...    []  \n",
       "14               No problem at all, see you in a bit!    []  \n",
       "15  Just let them know you're  here for badminton ...    []  \n",
       "16                                   We're on court 5    []  \n",
       "17                                                Ok.    []  \n",
       "18                                      Just got here    []  \n",
       "19                             Will get changed first    []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Participants', 'Message']) # Reading in the data in a dataframe form\n",
    "clean_data[\"Date\"] = pd.to_datetime(clean_data[\"Date\"])# making sure the date column is in a datetime format.  \n",
    "clean_data[\"emoji\"] = clean_data[\"Message\"].apply(split_count) # Applying the emoji function to extract the emojis from the messages.\n",
    "\n",
    "clean_data.head(20) # Having a look at the first 10 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf5529",
   "metadata": {},
   "source": [
    "Getting rid of non useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13cf54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data[clean_data.Message != '<Media omitted>']\n",
    "clean_data = clean_data[clean_data.Message != 'This message was deleted']\n",
    "clean_data = clean_data[clean_data.Message != 'You were added'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95570c04",
   "metadata": {},
   "source": [
    "Tokenizing, removing stop words and lemmatizing the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925bfd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aiyinchen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aiyinchen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/aiyinchen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c2d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for words in clean_data['Message']:\n",
    "    only_letters = re.sub(\"[^a-zA-Z]\", \" \",words)\n",
    "    tokens = nltk.word_tokenize(only_letters) #tokenize the sentences\n",
    "    lower_case = [l.lower() for l in tokens] #convert all letters to lower case\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case)) #Remove stopwords from the comments\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result] #lemmatizes the words i.e convert similar words to their\n",
    "    # base form while still considering the context in which the words are used \n",
    "    \n",
    "    messages.append(' '.join(lemmas))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ce82e",
   "metadata": {},
   "source": [
    "WordCloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a1810b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Let's use worldcloud to visualize the messages\u001b[39;00m\n\u001b[1;32m      2\u001b[0m unique_string\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(messages)\n\u001b[0;32m----> 3\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfont_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[1;32m    511\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[1;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[1;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[1;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[1;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[1;32m    675\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "#Let's use worldcloud to visualize the messages\n",
    "unique_string=(\" \").join(messages)\n",
    "wordcloud = WordCloud(width = 2000, height = 1000,font_path='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc',background_color='white').generate(unique_string)\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c41c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aiyinchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hi aiyin</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey nic</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi nic</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leisure centre</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message edited</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nic able</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finsbury leisure</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nic yes</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem wednesday</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm wednesday</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probably lot</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem bit</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able come</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really enjoyed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running min</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sesh total</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sesh yesterday</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session court</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuttle day</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sesh evening</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm problem</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm tuesday</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm tomorrow</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moberly sport</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm finsbury</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm early</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal sort</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect bring</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okayy let</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok sure</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok message</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nw nb</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice sesh</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nic nice</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nic aiyin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na wed</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slightly earlier</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smash downwards</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry got</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry running</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuesday thats</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type personal</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually flexible</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wan na</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want improve</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wed check</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wed look</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wednesday good</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wednesday pm</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week kensington</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "hi aiyin           3\n",
       "hey nic            3\n",
       "hi nic             3\n",
       "leisure centre     3\n",
       "message edited     2\n",
       "nic able           2\n",
       "finsbury leisure   2\n",
       "nic yes            2\n",
       "problem wednesday  1\n",
       "pm wednesday       1\n",
       "probably lot       1\n",
       "problem bit        1\n",
       "able come          1\n",
       "really enjoyed     1\n",
       "running min        1\n",
       "sesh total         1\n",
       "sesh yesterday     1\n",
       "session court      1\n",
       "shuttle day        1\n",
       "sesh evening       1\n",
       "pm problem         1\n",
       "pm tuesday         1\n",
       "pm tomorrow        1\n",
       "moberly sport      1\n",
       "pm finsbury        1\n",
       "pm early           1\n",
       "personal sort      1\n",
       "perfect bring      1\n",
       "okayy let          1\n",
       "ok sure            1\n",
       "ok message         1\n",
       "nw nb              1\n",
       "nice sesh          1\n",
       "nic nice           1\n",
       "nic aiyin          1\n",
       "na wed             1\n",
       "slightly earlier   1\n",
       "smash downwards    1\n",
       "sorry got          1\n",
       "sorry running      1\n",
       "tuesday thats      1\n",
       "type personal      1\n",
       "usually flexible   1\n",
       "wan na             1\n",
       "want improve       1\n",
       "wed check          1\n",
       "wed look           1\n",
       "wednesday good     1\n",
       "wednesday pm       1\n",
       "week kensington    1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co = CountVectorizer(ngram_range=(2,2),stop_words='english')\n",
    "counts = co.fit_transform(messages)\n",
    "pd.DataFrame(counts.sum(axis=0),columns=co.get_feature_names()).T.sort_values(0,ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46a6fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He --> nsubj\n",
      "went --> ROOT\n",
      "to --> aux\n",
      "play --> advcl\n",
      "basketball --> dobj\n"
     ]
    }
   ],
   "source": [
    "# dependency parsing\n",
    "for token in doc:\n",
    "    print(token.text, \"-->\", token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63dd437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basketball\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    # check token pos\n",
    "    if token.pos_=='NOUN':\n",
    "        # print token\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66458631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"08085f07a30142ca977ad28cd298b61c-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">play</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">basketball</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08085f07a30142ca977ad28cd298b61c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08085f07a30142ca977ad28cd298b61c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08085f07a30142ca977ad28cd298b61c-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08085f07a30142ca977ad28cd298b61c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08085f07a30142ca977ad28cd298b61c-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08085f07a30142ca977ad28cd298b61c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08085f07a30142ca977ad28cd298b61c-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08085f07a30142ca977ad28cd298b61c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy \n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c68676",
   "metadata": {},
   "source": [
    "Use Spark NLP to extract dates from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d6bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/27 09:50:12 WARN Utils: Your hostname, Ais-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.192.76 instead (on interface en0)\n",
      "23/09/27 09:50:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/aiyinchen/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/aiyinchen/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/aiyinchen/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2d8ab8e6-024f-47cd-bd2c-30c010d0c62d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.1 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.15.0 in central\n",
      ":: resolution report :: resolve 3712ms :: artifacts dl 58ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.1.1 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.15.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   75  |   0   |   0   |   3   ||   72  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2d8ab8e6-024f-47cd-bd2c-30c010d0c62d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 72 already retrieved (0kB/56ms)\n",
      "23/09/27 09:50:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# Start Spark Session\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdde7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain datetime values Whatsapp timestamp\n",
    "import datetime\n",
    "anchor_year = clean_data.Date[0].year\n",
    "anchor_month = clean_data.Date[0].month\n",
    "anchor_day = clean_data.Date[0].day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ef0932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules and classes\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import (\n",
    "    DateMatcher,\n",
    "    MultiDateMatcher\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "# Step 1: Transforms raw texts to `document` annotation\n",
    "document_assembler = (\n",
    "    DocumentAssembler()\n",
    "    .setInputCol(\"text\")\n",
    "    .setOutputCol(\"document\")\n",
    ")\n",
    "# Step 2: Extracts one date information from text\n",
    "date = (\n",
    "    DateMatcher()\n",
    "    .setInputCols(\"document\") \n",
    "    .setOutputCol(\"date\") \n",
    "    .setOutputFormat(\"yyyy/MM/dd\")\n",
    ")\n",
    "# Step 3: Extracts multiple date information from text. Set anchor day, month, year\n",
    "anchorDate = (\n",
    "    MultiDateMatcher()\n",
    "    .setInputCols(\"document\") \n",
    "    .setOutputCol(\"multi_date\") \n",
    "    .setOutputFormat(\"MM/dd/yy\")\n",
    "    .setAnchorDateYear(anchor_year)\n",
    "    .setAnchorDateMonth(anchor_month)\n",
    "    .setAnchorDateDay(anchor_day)\n",
    ")\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[document_assembler, date, anchorDate])\n",
    "text_list = [\"See you on next monday.\",  \n",
    "             \"She was born on 02/03/1966.\", \n",
    "             \"The project started yesterday and will finish next year.\", \n",
    "             \"She will graduate by July 2023.\", \n",
    "             \"She will visit doctor tomorrow and next month again.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "89c9eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "|text                                                                                                   |date        |multi_date|\n",
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "|Hi Nic, this is Aiyin here.. We were in touch on Superprof                                             |[]          |[]        |\n",
      "|I just checked, i didnt manage to book 9-10pm for Wednesday, only 6-7pm, would it be too early for you?|[2023/09/27]|[]        |\n",
      "|Hi Aiyin, 6-7pm is not a problem                                                                       |[2023/09/27]|[]        |\n",
      "|My time is usually very flexible as long I don’t have client meetings                                  |[]          |[]        |\n",
      "|Thats perfect! I'll bring shuttles for the day, anything specific you'd like to work on?               |[]          |[]        |\n",
      "|Thanks. Just want to improve on general play                                                           |[]          |[]        |\n",
      "|Probably have a lot of bad habits. Struggle to smash downwards                                         |[]          |[]        |\n",
      "|Ahh okayy lets see what we can work on for Wed.. Look forward to see you then!                         |[]          |[]        |\n",
      "|Me too! Thanks                                                                                         |[]          |[]        |\n",
      "|Hi Aiyin, is this at the Moberly Sports Centre NW10 3NB?                                               |[]          |[]        |\n",
      "|Hey Nic, yes its at Moberly on Wed                                                                     |[]          |[]        |\n",
      "|Hi Nic, you able to come slightly earlier at 5.30-6.30pm tomorrow?                                     |[2023/09/28]|[09/02/23]|\n",
      "|Sure! See you then                                                                                     |[]          |[]        |\n",
      "|Sorry running 10min late. Took a long time to get a car <This message was edited>                      |[]          |[]        |\n",
      "|No problem at all, see you in a bit!                                                                   |[]          |[]        |\n",
      "|Just let them know you're  here for badminton when you come in                                         |[]          |[]        |\n",
      "|We're on court 5                                                                                       |[]          |[]        |\n",
      "|Ok.                                                                                                    |[]          |[]        |\n",
      "|Just got here                                                                                          |[]          |[]        |\n",
      "|Will get changed first                                                                                 |[]          |[]        |\n",
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    TimestampType,\n",
    "    StructType,\n",
    "    StructField\n",
    ")\n",
    "\n",
    "# Create a dataframe\n",
    "text_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
    "# Fit the dataframe and get predictions\n",
    "result = nlpPipeline.fit(text_df).transform(text_df)\n",
    "# Display the extracted date information in a dataframe\n",
    "result.selectExpr(\"text\",\"date.result as date\", \"multi_date.result as multi_date\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45832345",
   "metadata": {},
   "source": [
    "Try the NLU task on existing WhatsApp Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acc0e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Hi Nic, this is A...|\n",
      "|I just checked, i...|\n",
      "|Hi Aiyin, 6-7pm i...|\n",
      "|My time is usuall...|\n",
      "|Thats perfect! I'...|\n",
      "|Thanks. Just want...|\n",
      "|Probably have a l...|\n",
      "|Ahh okayy lets se...|\n",
      "|      Me too! Thanks|\n",
      "|Hi Aiyin, is this...|\n",
      "|Hey Nic, yes its ...|\n",
      "|Hi Nic, you able ...|\n",
      "|  Sure! See you then|\n",
      "|Sorry running 10m...|\n",
      "|No problem at all...|\n",
      "|Just let them kno...|\n",
      "|    We're on court 5|\n",
      "|                 Ok.|\n",
      "|       Just got here|\n",
      "|Will get changed ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+\n",
      "|          timestamp|\n",
      "+-------------------+\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-01 00:00:00|\n",
      "|2023-09-02 00:00:00|\n",
      "|2023-09-03 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "|2023-09-06 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Actual code\n",
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    TimestampType,\n",
    "    StructType,\n",
    "    StructField, \n",
    "    ArrayType,\n",
    "    MapType,\n",
    "    FloatType\n",
    ")\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import lit  # To create a constant column\n",
    "\n",
    "# extract the messages from clean_data\n",
    "messages = clean_data.Message\n",
    "text_list = messages.values.tolist()\n",
    "timestamp = clean_data.Date\n",
    "date_list = timestamp.tolist()\n",
    "date_list_df = pd.DataFrame({'timestamp': date_list})\n",
    "\n",
    "# Create a dataframe\n",
    "text_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
    "#timestamp_df = spark.createDataFrame(date_list, TimestampType()).toDF(\"timestamp\")\n",
    "# Define the schema for the PySpark DataFrame\n",
    "schema = StructType([StructField(\"timestamp\", TimestampType(), True)])\n",
    "timestamp_df = spark.createDataFrame(date_list_df, schema=schema)\n",
    "\n",
    "text_df.show()\n",
    "timestamp_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "18dd7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+------------+-----------+\n",
      "|                text|          timestamp|anchor_day|anchor_month|anchor_year|\n",
      "+--------------------+-------------------+----------+------------+-----------+\n",
      "|Hi Nic, this is A...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|I just checked, i...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Hi Aiyin, 6-7pm i...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|My time is usuall...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Thats perfect! I'...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Thanks. Just want...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Probably have a l...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Ahh okayy lets se...|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|      Me too! Thanks|2023-09-01 00:00:00|         1|           9|       2023|\n",
      "|Hi Aiyin, is this...|2023-09-02 00:00:00|         2|           9|       2023|\n",
      "|Hey Nic, yes its ...|2023-09-03 00:00:00|         3|           9|       2023|\n",
      "|Hi Nic, you able ...|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|  Sure! See you then|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|Sorry running 10m...|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|No problem at all...|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|Just let them kno...|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|    We're on court 5|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|                 Ok.|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|       Just got here|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "|Will get changed ...|2023-09-06 00:00:00|         6|           9|       2023|\n",
      "+--------------------+-------------------+----------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the dataframe and get predictions\n",
    "#result = nlpPipeline.fit(text_df).transform(text_df)\n",
    "# Display the extracted date information in a dataframe\n",
    "#result.selectExpr(\"text\",\"date.result as date\", \"multi_date.result as multi_date\").show(truncate=False)\n",
    "#result.selectExpr(\"text\",\"timestamp\").show(truncate=False)\n",
    "\n",
    "# Add unique IDs to both DataFrames\n",
    "text_df = text_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "timestamp_df = timestamp_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "# Join the two DataFrames using the common 'id' column\n",
    "joined_df = text_df.join(timestamp_df, \"id\").drop(\"id\")\n",
    "\n",
    "# Define a UDF (User Defined Function) to extract anchor_day, anchor_month, and anchor_year\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "@udf(IntegerType())\n",
    "def extract_day(timestamp):\n",
    "    return timestamp.day\n",
    "\n",
    "@udf(IntegerType())\n",
    "def extract_month(timestamp):\n",
    "    return timestamp.month\n",
    "\n",
    "@udf(IntegerType())\n",
    "def extract_year(timestamp):\n",
    "    return timestamp.year\n",
    "\n",
    "# Add columns for anchor_day, anchor_month, and anchor_year to the joined DataFrame\n",
    "joined_df = joined_df.withColumn(\"anchor_day\", extract_day(joined_df[\"timestamp\"]))\n",
    "joined_df = joined_df.withColumn(\"anchor_month\", extract_month(joined_df[\"timestamp\"]))\n",
    "joined_df = joined_df.withColumn(\"anchor_year\", extract_year(joined_df[\"timestamp\"]))\n",
    "\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1366a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Hi Nic, this is A...|[{document, 0, 57...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|                text|            document|                date|multi_date|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|I just checked, i...|[{document, 0, 10...|[{date, 41, 44, 2...|        []|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|                text|            document|                date|multi_date|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Hi Aiyin, 6-7pm i...|[{document, 0, 31...|[{date, 12, 14, 2...|        []|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|My time is usuall...|[{document, 0, 68...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Thats perfect! I'...|[{document, 0, 87...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Thanks. Just want...|[{document, 0, 43...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Probably have a l...|[{document, 0, 61...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Ahh okayy lets se...|[{document, 0, 77...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "1\n",
      "+--------------+--------------------+----+----------+\n",
      "|          text|            document|date|multi_date|\n",
      "+--------------+--------------------+----+----------+\n",
      "|Me too! Thanks|[{document, 0, 13...|  []|        []|\n",
      "+--------------+--------------------+----+----------+\n",
      "\n",
      "2\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Hi Aiyin, is this...|[{document, 0, 55...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "3\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Hey Nic, yes its ...|[{document, 0, 33...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                date|          multi_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Hi Nic, you able ...|[{document, 0, 65...|[{date, 57, 64, 2...|[{date, 57, 64, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "6\n",
      "+------------------+--------------------+----+----------+\n",
      "|              text|            document|date|multi_date|\n",
      "+------------------+--------------------+----+----------+\n",
      "|Sure! See you then|[{document, 0, 17...|  []|        []|\n",
      "+------------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Sorry running 10m...|[{document, 0, 80...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|No problem at all...|[{document, 0, 35...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Just let them kno...|[{document, 0, 61...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+----------------+--------------------+----+----------+\n",
      "|            text|            document|date|multi_date|\n",
      "+----------------+--------------------+----+----------+\n",
      "|We're on court 5|[{document, 0, 15...|  []|        []|\n",
      "+----------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+----+--------------------+----+----------+\n",
      "|text|            document|date|multi_date|\n",
      "+----+--------------------+----+----------+\n",
      "| Ok.|[{document, 0, 2,...|  []|        []|\n",
      "+----+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+-------------+--------------------+----+----------+\n",
      "|         text|            document|date|multi_date|\n",
      "+-------------+--------------------+----+----------+\n",
      "|Just got here|[{document, 0, 12...|  []|        []|\n",
      "+-------------+--------------------+----+----------+\n",
      "\n",
      "6\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Will get changed ...|[{document, 0, 21...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Aiyin 🔥: Hey Nic...|[{document, 0, 84...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                date|          multi_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|For next week, I'...|[{document, 0, 16...|[{date, 4, 12, 20...|[{date, 4, 12, 09...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                date|          multi_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Aiyin 🔥: For yes...|[{document, 0, 19...|[{date, 74, 193, ...|[{date, 74, 193, ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                date|          multi_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Hey Aiyin, Thanks...|[{document, 0, 83...|[{date, 31, 39, 2...|[{date, 31, 39, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|I’ll transfer the...|[{document, 0, 30...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|                text|            document|                date|multi_date|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|lets do 9-10pm on...|[{document, 0, 85...|[{date, 10, 13, 2...|        []|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|That’s ok for me....|[{document, 0, 42...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "7\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|alright, see you ...|[{document, 0, 21...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "8\n",
      "+-----+--------------------+----+----------+\n",
      "| text|            document|date|multi_date|\n",
      "+-----+--------------------+----+----------+\n",
      "|Paid!|[{document, 0, 4,...|  []|        []|\n",
      "+-----+--------------------+----+----------+\n",
      "\n",
      "11\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                date|          multi_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Hi Aiyin, so sorr...|[{document, 0, 68...|[{date, 61, 68, 2...|[{date, 61, 68, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "11\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Are you free on W...|[{document, 0, 25...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "11\n",
      "+--------------------+--------------------+----+----------+\n",
      "|                text|            document|date|multi_date|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|Hey Nic, yes no p...|[{document, 0, 14...|  []|        []|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n",
      "11\n",
      "+-------+--------------------+----+----------+\n",
      "|   text|            document|date|multi_date|\n",
      "+-------+--------------------+----+----------+\n",
      "|Thanks!|[{document, 0, 6,...|  []|        []|\n",
      "+-------+--------------------+----+----------+\n",
      "\n",
      "12\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|                text|            document|                date|multi_date|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Hi Nic, would you...|[{document, 0, 83...|[{date, 32, 35, 2...|        []|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/27 15:54:27 WARN DAGScheduler: Broadcasting large task binary with size 1494.3 KiB\n",
      "23/09/27 15:54:27 WARN DAGScheduler: Broadcasting large task binary with size 1494.3 KiB\n",
      "23/09/27 15:54:28 WARN DAGScheduler: Broadcasting large task binary with size 1494.3 KiB\n",
      "23/09/27 15:54:28 WARN DAGScheduler: Broadcasting large task binary with size 1494.3 KiB\n",
      "23/09/27 15:54:31 WARN DAGScheduler: Broadcasting large task binary with size 1494.3 KiB\n",
      "[Stage 3387:===================================================>  (89 + 5) / 94]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "|text                                                                                                   |date        |multi_date|\n",
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "|Hi Nic, this is Aiyin here.. We were in touch on Superprof                                             |[]          |[]        |\n",
      "|I just checked, i didnt manage to book 9-10pm for Wednesday, only 6-7pm, would it be too early for you?|[2023/09/27]|[]        |\n",
      "|Hi Aiyin, 6-7pm is not a problem                                                                       |[2023/09/27]|[]        |\n",
      "|My time is usually very flexible as long I don’t have client meetings                                  |[]          |[]        |\n",
      "|Thats perfect! I'll bring shuttles for the day, anything specific you'd like to work on?               |[]          |[]        |\n",
      "|Thanks. Just want to improve on general play                                                           |[]          |[]        |\n",
      "|Probably have a lot of bad habits. Struggle to smash downwards                                         |[]          |[]        |\n",
      "|Ahh okayy lets see what we can work on for Wed.. Look forward to see you then!                         |[]          |[]        |\n",
      "|Me too! Thanks                                                                                         |[]          |[]        |\n",
      "|Hi Aiyin, is this at the Moberly Sports Centre NW10 3NB?                                               |[]          |[]        |\n",
      "|Hey Nic, yes its at Moberly on Wed                                                                     |[]          |[]        |\n",
      "|Hi Nic, you able to come slightly earlier at 5.30-6.30pm tomorrow?                                     |[2023/09/28]|[09/02/23]|\n",
      "|Sure! See you then                                                                                     |[]          |[]        |\n",
      "|Sorry running 10min late. Took a long time to get a car <This message was edited>                      |[]          |[]        |\n",
      "|No problem at all, see you in a bit!                                                                   |[]          |[]        |\n",
      "|Just let them know you're  here for badminton when you come in                                         |[]          |[]        |\n",
      "|We're on court 5                                                                                       |[]          |[]        |\n",
      "|Ok.                                                                                                    |[]          |[]        |\n",
      "|Just got here                                                                                          |[]          |[]        |\n",
      "|Will get changed first                                                                                 |[]          |[]        |\n",
      "+-------------------------------------------------------------------------------------------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Set the anchor day, month and year for each row.\n",
    "temp = joined_df.select(\"anchor_day\", \"anchor_month\", \"anchor_year\")\n",
    "\n",
    "#anchor_day_list = joined_df.select(\"anchor_day\").rdd.flatMap(lambda x: x).collect()\n",
    "#anchor_month_list = joined_df.select(\"anchor_month\").rdd.flatMap(lambda x: x).collect()\n",
    "#anchor_year_list = joined_df.select(\"anchor_year\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "result_schema = StructType([\n",
    "    StructField('text', StringType(), True),\n",
    "    # Add more fields as needed based on your NLP pipeline output\n",
    "    # For example, if your NLP pipeline outputs a column named 'result', you can add it like this:\n",
    "    StructField('document', ArrayType(\n",
    "        StructType([\n",
    "            StructField('annotatorType', StringType(), True),\n",
    "            StructField('begin', IntegerType(), True),\n",
    "            StructField('end', IntegerType(), True),\n",
    "            StructField('result', StringType(), True),\n",
    "            StructField('metadata', MapType(StringType(), StringType()), True),\n",
    "            StructField('embeddings', ArrayType(FloatType()), True)\n",
    "        ])\n",
    "    ), True),    \n",
    "    StructField('date', ArrayType(\n",
    "        StructType([\n",
    "            StructField('annotatorType', StringType(), True),\n",
    "            StructField('begin', IntegerType(), True),\n",
    "            StructField('end', IntegerType(), True),\n",
    "            StructField('result', StringType(), True),\n",
    "            StructField('metadata', MapType(StringType(), StringType()), True),\n",
    "            StructField('embeddings', ArrayType(FloatType()), True)\n",
    "        ])\n",
    "    ), True),\n",
    "    StructField('multi_date', ArrayType(\n",
    "        StructType([\n",
    "            StructField('annotatorType', StringType(), True),\n",
    "            StructField('begin', IntegerType(), True),\n",
    "            StructField('end', IntegerType(), True),\n",
    "            StructField('result', StringType(), True),\n",
    "            StructField('metadata', MapType(StringType(), StringType()), True),\n",
    "            StructField('embeddings', ArrayType(FloatType()), True)\n",
    "        ])\n",
    "    ), True)\n",
    "])\n",
    "\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list = []\n",
    "result_df = spark.createDataFrame([], schema = result_schema)\n",
    "# Iterate through each row in the DataFrame\n",
    "for row in joined_df.rdd.collect():\n",
    "    # Extract text and date information from the row\n",
    "    text = [row[\"text\"]]\n",
    "    anchor_day = row[\"anchor_day\"]\n",
    "    anchor_month = row[\"anchor_month\"]\n",
    "    anchor_year = row[\"anchor_year\"]\n",
    "        \n",
    "    text_df = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "    print(anchor_day)\n",
    "    result = nlpPipeline.fit(text_df).transform(text_df)\n",
    "    result.show()\n",
    "    \n",
    "    # Remove the header row (if it's the first row)\n",
    "    if result.count() == 0:\n",
    "        result = result.withColumn(\"text\", lit(\"text\"))\n",
    "    \n",
    "    result_df = result_df.union(result)\n",
    "    \n",
    "\n",
    "#result_df.show() \n",
    "\n",
    "result_df.selectExpr(\"text\",\"date.result as date\", \"multi_date.result as multi_date\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce70d656",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (143592066.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [55]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for \"text\" in row_dict:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "# Set the anchor day, month and year for each row.\n",
    "temp = joined_df.select(\"anchor_day\", \"anchor_month\", \"anchor_year\")\n",
    "\n",
    "anchor_day_list = joined_df.select(\"anchor_day\").rdd.flatMap(lambda x: x).collect()\n",
    "anchor_month_list = joined_df.select(\"anchor_month\").rdd.flatMap(lambda x: x).collect()\n",
    "anchor_year_list = joined_df.select(\"anchor_year\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for row in joined_df.rdd.collect():\n",
    "    # Extract text and date information from the row\n",
    "    text = str(row[\"text\"])\n",
    "    anchor_day = row[\"anchor_day\"]\n",
    "    anchor_month = row[\"anchor_month\"]\n",
    "    anchor_year = row[\"anchor_year\"]\n",
    "    \n",
    "    # Create a new Row with the extracted values\n",
    "    single_row = Row(text=text, anchor_day=anchor_day, anchor_month=anchor_month, anchor_year=anchor_year)\n",
    "    \n",
    "    # Apply the NLP pipeline to the single row and collect the result\n",
    "    result = nlpPipeline.fit(spark.createDataFrame([single_row])).transform(spark.createDataFrame([single_row]))\n",
    "    \n",
    "    # Append the result as a Row to the result list\n",
    "    result_list.append(Row(**result.first().asDict()))\n",
    "\n",
    "result_list.show()\n",
    "\n",
    "# loop through each row of the pyspark Dataframe and apply nlpPipeline to \"text\"\n",
    "# Define a function to drop the 'document' entry from a Row\n",
    "def apply_pipeline(row):\n",
    "    # Convert the Row to a dictionary\n",
    "    row_dict = row.asDict()\n",
    "    \n",
    "    # Check if the \"document\" entry exists in the dictionary\n",
    "    for \"text\" in row_dict:\n",
    "        # Remove the \"document\" entry from the dictionary\n",
    "        del row_dict[\"document\"]\n",
    "    \n",
    "    if \"date\" in row_dict:\n",
    "        # Typecast \"date\" to DateType()\n",
    "        print()\n",
    "        row_dict[\"date\"] = lit(row_dict[\"date\"]).cast(DateType())\n",
    "        \n",
    "    #if \"multi_date\" in row_dict:\n",
    "        # Typecast \"multi_date\" to DateType()\n",
    "        #row_dict[\"multi_date\"] = row_dict[\"multi_date\"].cast(DateType())\n",
    "    \n",
    "    \n",
    "    # Create a new Row from the modified dictionary\n",
    "    return Row(**row_dict)\n",
    "\n",
    "# Use list comprehension to drop the \"document\" entry from each Row in the list\n",
    "#new_result_list = [apply_pipeline(row) for row in result_list]\n",
    "\n",
    "\n",
    "\n",
    "#print(anchor_day[0])\n",
    "#temp.show()\n",
    "#print(anchor_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6eb4dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'anchor_day[0]'>\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------+\n",
      "|text                                                                                                                                                                                              |date        |multi_date          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------+\n",
      "|Hi Nic, this is Aiyin here.. We were in touch on Superprof                                                                                                                                        |[]          |[]                  |\n",
      "|I just checked, i didnt manage to book 9-10pm for Wednesday, only 6-7pm, would it be too early for you?                                                                                           |[2023/09/27]|[]                  |\n",
      "|Hi Aiyin, 6-7pm is not a problem                                                                                                                                                                  |[2023/09/27]|[]                  |\n",
      "|My time is usually very flexible as long I don’t have client meetings                                                                                                                             |[]          |[]                  |\n",
      "|Thats perfect! I'll bring shuttles for the day, anything specific you'd like to work on?                                                                                                          |[]          |[]                  |\n",
      "|Thanks. Just want to improve on general play                                                                                                                                                      |[]          |[]                  |\n",
      "|Probably have a lot of bad habits. Struggle to smash downwards                                                                                                                                    |[]          |[]                  |\n",
      "|Ahh okayy lets see what we can work on for Wed.. Look forward to see you then!                                                                                                                    |[]          |[]                  |\n",
      "|Me too! Thanks                                                                                                                                                                                    |[]          |[]                  |\n",
      "|Hi Aiyin, is this at the Moberly Sports Centre NW10 3NB?                                                                                                                                          |[]          |[]                  |\n",
      "|Hey Nic, yes its at Moberly on Wed                                                                                                                                                                |[]          |[]                  |\n",
      "|Hi Nic, you able to come slightly earlier at 5.30-6.30pm tomorrow?                                                                                                                                |[2023/09/28]|[09/02/23]          |\n",
      "|Sure! See you then                                                                                                                                                                                |[]          |[]                  |\n",
      "|Sorry running 10min late. Took a long time to get a car <This message was edited>                                                                                                                 |[]          |[]                  |\n",
      "|No problem at all, see you in a bit!                                                                                                                                                              |[]          |[]                  |\n",
      "|Just let them know you're  here for badminton when you come in                                                                                                                                    |[]          |[]                  |\n",
      "|We're on court 5                                                                                                                                                                                  |[]          |[]                  |\n",
      "|Ok.                                                                                                                                                                                               |[]          |[]                  |\n",
      "|Just got here                                                                                                                                                                                     |[]          |[]                  |\n",
      "|Will get changed first                                                                                                                                                                            |[]          |[]                  |\n",
      "|Aiyin 🔥: Hey Nic! Was a nice sesh with you last evening. Hope you found it useful :)                                                                                                             |[]          |[]                  |\n",
      "|For next week, I'll be at Kensington Leisure Centre on Tuesday, courts at Moberly seem booked out on Wed so would have to check other locations if we wanna do Wed                                |[2023/10/04]|[09/08/23]          |\n",
      "|Aiyin 🔥: For yesterday's sesh its £45 in total (£35 for the session and £10 for the court). Here's my bank account: 🙏 Acc name: A Y CHEN Acc type: Personal Sort Code: 20-80-14 Acc No: 63286606|[6606/01/10]|[01/10/06, 08/31/23]|\n",
      "|Hey Aiyin, Thanks for the sesh yesterday. Really enjoyed it! Tuesday is good for me.                                                                                                              |[2023/09/26]|[08/31/23]          |\n",
      "|I’ll transfer the funds tonight                                                                                                                                                                   |[]          |[]                  |\n",
      "|lets do 9-10pm on Tuesday if thats ok, not sure if thats too late for you getting home                                                                                                            |[2023/09/27]|[]                  |\n",
      "|That’s ok for me. <This message was edited>                                                                                                                                                       |[]          |[]                  |\n",
      "|alright, see you then!                                                                                                                                                                            |[]          |[]                  |\n",
      "|Paid!                                                                                                                                                                                             |[]          |[]                  |\n",
      "|Hi Aiyin, so sorry. I got my dates wrong! I am actually busy tomorrow                                                                                                                             |[2023/09/28]|[09/02/23]          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the anchor day, month and year for each row.\n",
    "print(joined_df.anchor_day[0])\n",
    "\n",
    "# Fit the dataframe and get predictions\n",
    "result = nlpPipeline.fit(joined_df).transform(joined_df)\n",
    "# Display the extracted date information in a dataframe\n",
    "result.selectExpr(\"text\",\"date.result as date\", \"multi_date.result as multi_date\").show(30,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28122946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
